# app.py
import os
from pathlib import Path
import numpy as np
import streamlit as st
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.applications.densenet import preprocess_input
from tensorflow.keras import backend as K
from PIL import Image
import cv2
import gdown
import requests

# ============================= Page / Constants =============================
st.set_page_config(page_title="CXR Pneumonia Classifier (DenseNet121)", layout="wide")
CLASS_NAMES = ["NORMAL", "PNEUMONIA"]
IMG_SIZE = (224, 224)

# Google Drive FILE ID (Secrets ìš°ì„ )
FILE_ID = st.secrets.get("MODEL_FILE_ID", "1UPxtL1kx8a38z9fxlBRljNn8n6T4LL_l")
MODEL_DIR = Path("models")
MODEL_LOCAL = MODEL_DIR / "densenet121_best_9.keras"
MODEL_DIR.mkdir(parents=True, exist_ok=True)

# Drive ë§‰í ë•Œ í´ë°± URL (HF/GitHub ë“±)
HTTP_FALLBACK_URL = st.secrets.get("MODEL_DIRECT_URL", "")
TIMEOUT = 120

# ============================= Utils: download & load model =============================
def _http_download(url: str, out: Path) -> bool:
    try:
        with requests.get(url, stream=True, timeout=TIMEOUT) as r:
            r.raise_for_status()
            with open(out, "wb") as f:
                for chunk in r.iter_content(1 << 20):
                    if chunk:
                        f.write(chunk)
        return out.exists() and out.stat().st_size > 0
    except Exception as e:
        st.warning(f"HTTP download failed: {e}")
        return False

@st.cache_data(show_spinner=False)
def ensure_model_file_cached() -> str:
    if MODEL_LOCAL.exists() and MODEL_LOCAL.stat().st_size > 0:
        return str(MODEL_LOCAL)
    try:
        with st.spinner("ğŸ“¥ Downloading model from Google Drive (gdown)â€¦"):
            gdown.download(id=FILE_ID, output=str(MODEL_LOCAL), quiet=False, use_cookies=False, fuzzy=True)
        if MODEL_LOCAL.exists() and MODEL_LOCAL.stat().st_size > 0:
            return str(MODEL_LOCAL)
    except Exception as e:
        st.warning(f"gdown failed: {e}")
    if HTTP_FALLBACK_URL:
        with st.spinner("ğŸŒ Downloading model via direct URLâ€¦"):
            if _http_download(HTTP_FALLBACK_URL, MODEL_LOCAL):
                return str(MODEL_LOCAL)
    raise RuntimeError("ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: Google Drive/ì§ë§í¬ ëª¨ë‘ ë¶ˆê°€í•©ë‹ˆë‹¤.")

@st.cache_resource(show_spinner=False)
def load_model(model_path: str):
    return keras.models.load_model(
        model_path,
        custom_objects={"preprocess_input": preprocess_input},
        safe_mode=False,
        compile=False,
    )

# ============================= Grad-CAM helpers =============================
def find_base_model(m: keras.Model):
    """DenseNet ë°±ë³¸(ì„œë¸Œëª¨ë¸) ë˜ëŠ” ê°€ì¥ ì•ˆìª½ Modelì„ ë°˜í™˜."""
    try:
        return m.get_layer("densenet121")
    except Exception:
        for lyr in m.layers[::-1]:
            if isinstance(lyr, keras.Model):
                return lyr
        return m

def _is_4d(layer) -> bool:
    """K.int_shapeë¡œ ì•ˆì „í•˜ê²Œ rank==4 íŒì •."""
    try:
        shp = K.int_shape(layer.output)  # (None,H,W,C)
        return (shp is not None) and (len(shp) == 4)
    except Exception:
        return False

def list_4d_layers(model_or_layer):
    """í•œ ë‹¨ê³„ ìì‹ ì¤‘ 4D ì¶œë ¥ ë ˆì´ì–´ ëª©ë¡."""
    if isinstance(model_or_layer, keras.Model):
        return [lyr for lyr in model_or_layer.layers if _is_4d(lyr)]
    return []

def find_last_conv4d_layer_recursive(layer_or_model):
    """ëª¨ë¸ íŠ¸ë¦¬ë¥¼ DFSë¡œ í›‘ì–´ ë§ˆì§€ë§‰ 4D(B,H,W,C) ë ˆì´ì–´ë¥¼ ë°˜í™˜."""
    last = None
    if isinstance(layer_or_model, keras.Model):
        for lyr in layer_or_model.layers:
            cand = find_last_conv4d_layer_recursive(lyr)
            if cand is not None:
                last = cand
    else:
        if _is_4d(layer_or_model):
            last = layer_or_model
    return last

def pick_best_densenet_conv_layer(base: keras.Model):
    """
    DenseNet ë‚´ë¶€ 4D ë ˆì´ì–´ ì¤‘ ì´ë¦„ì— 'concat'/'relu' í¬í•¨ ë ˆì´ì–´ë¥¼ ìš°ì„ .
    ì—†ìœ¼ë©´ ë§ˆì§€ë§‰ 4D ë ˆì´ì–´.
    """
    four_d_layers = list_4d_layers(base)
    if not four_d_layers:
        return None
    preferred = [l for l in four_d_layers if ("concat" in l.name.lower()) or ("relu" in l.name.lower())]
    return (preferred[-1] if preferred else four_d_layers[-1])

@tf.function
def _normalize_heatmap(x):
    x = tf.maximum(x, 0.0)
    mx = tf.reduce_max(x)
    return tf.where(mx > 0, x / mx, x)

# ---------- ìƒˆ í´ë°± í¬í•¨ Grad-CAM ----------
def make_gradcam_heatmap(img_bchw, model: keras.Model, conv_layer):
    """
    conv_layer: ë ˆì´ì–´ 'ê°ì²´' (ì„œë¸Œëª¨ë¸ ë‚´ë¶€ í¬í•¨)
    img_bchw: float32, [1,H,W,3]
    Aâ†’Bâ†’C í´ë°±ìœ¼ë¡œ ë¬´ì¡°ê±´ íˆíŠ¸ë§µì„ ë°˜í™˜.
    """
    # ì…ë ¥ ë³´ì¥
    if not isinstance(img_bchw, np.ndarray):
        img_bchw = np.array(img_bchw)
    if img_bchw.dtype != np.float32:
        img_bchw = img_bchw.astype(np.float32)

    if conv_layer is None or not hasattr(conv_layer, "output"):
        raise ValueError("ìœ íš¨í•œ 4D conv ë ˆì´ì–´ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

    # ---------- ë°©ë²• A: ì„œë¸Œëª¨ë¸ 2ë²ˆ í˜¸ì¶œ (í‘œì¤€) ----------
    try:
        last_conv_model = keras.Model(inputs=model.input, outputs=conv_layer.output)
        with tf.GradientTape() as tape:
            conv_out = last_conv_model(img_bchw, training=False)      # [N,Hc,Wc,C]
            preds    = model(img_bchw,        training=False)          # [N,1] or [N,C]

            if isinstance(preds, dict): preds = next(iter(preds.values()))
            if isinstance(preds, (list, tuple)): preds = preds[0]
            preds = tf.convert_to_tensor(preds)

            if isinstance(conv_out, (list, tuple)): conv_out = conv_out[0]
            conv_out = tf.convert_to_tensor(conv_out)
            tape.watch(conv_out)

            # (N,C) í‘œì¤€í™”
            if preds.shape.rank is None or preds.shape.rank == 0:
                preds = tf.reshape(preds, (-1, 1))
            elif preds.shape.rank == 1:
                preds = tf.expand_dims(preds, -1)

            class_channel = preds[:, 0] if preds.shape[-1] == 1 else preds[:, 1]

        grads = tape.gradient(class_channel, conv_out)
        if grads is None:
            raise RuntimeError("Gradients are None in method A.")

        if conv_out.shape.rank != 4:
            raise RuntimeError(f"Conv rank != 4 in method A: {conv_out.shape}")

        pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))  # [C]
        conv_out = conv_out[0]                                # [Hc,Wc,C]
        heatmap = tf.reduce_sum(conv_out * pooled_grads, axis=-1)
        return _normalize_heatmap(heatmap).numpy()
    except Exception:
        pass  # A ì‹¤íŒ¨ â†’ B ì‹œë„

    # ---------- ë°©ë²• B: K.function ê²½ë¡œ (ê·¸ë˜í”„ ë§¤ì¹­ ë¬¸ì œ ìš°íšŒ) ----------
    try:
        try:
            fetch_fn = K.function([model.input], [conv_layer.output, model.output])
            conv_out, preds = fetch_fn([img_bchw])
        except Exception:
            fetch_fn = K.function([model.input, K.learning_phase()],
                                  [conv_layer.output, model.output])
            conv_out, preds = fetch_fn([img_bchw, 0])

        conv_out = np.asarray(conv_out)
        preds    = np.asarray(preds)

        if conv_out.ndim != 4:
            raise RuntimeError(f"Conv rank != 4 in method B: {conv_out.shape}")

        if preds.ndim == 0:
            preds = preds.reshape(1, 1)
        elif preds.ndim == 1:
            preds = preds[:, None]

        # ì±„ë„ í‰ê·  í™œì„±ìœ¼ë¡œ ê·¼ì‚¬ ê°€ì¤‘ì¹˜
        weights = conv_out.mean(axis=(1, 2), keepdims=False)[0]  # [C]
        fmap    = conv_out[0]                                    # [Hc,Wc,C]
        heatmap = np.tensordot(fmap, weights, axes=([2], [0]))   # [Hc,Wc]
        heatmap = np.maximum(heatmap, 0.0)
        mx = heatmap.max()
        if mx > 0:
            heatmap = heatmap / mx
        return heatmap.astype(np.float32)
    except Exception:
        pass  # B ì‹¤íŒ¨ â†’ C ì‹œë„

    # ---------- ë°©ë²• C: Saliency(ì…ë ¥-ê·¸ë˜ë””ì–¸íŠ¸) í´ë°± ----------
    x = tf.convert_to_tensor(img_bchw)
    with tf.GradientTape() as tape:
        tape.watch(x)
        preds = model(x, training=False)
        if isinstance(preds, dict): preds = next(iter(preds.values()))
        if isinstance(preds, (list, tuple)): preds = preds[0]
        preds = tf.convert_to_tensor(preds)
        if preds.shape.rank == 1:
            preds = preds[None, :]
        class_channel = preds[:, 0] if preds.shape[-1] == 1 else preds[:, 1]
    grads = tape.gradient(class_channel, x)  # [1,H,W,3]
    sal = tf.reduce_max(tf.abs(grads), axis=-1)[0]  # [H,W]
    sal = sal / (tf.reduce_max(sal) + 1e-8)
    return sal.numpy().astype(np.float32)

def overlay_heatmap(rgb_uint8, heatmap, alpha=0.4):
    h, w = rgb_uint8.shape[:2]
    hm = cv2.resize(heatmap, (w, h))
    hm = np.uint8(255 * hm)
    jet = cv2.applyColorMap(hm, cv2.COLORMAP_JET)
    jet = cv2.cvtColor(jet, cv2.COLOR_BGR2RGB)
    out = (jet * alpha + rgb_uint8 * (1 - alpha)).clip(0, 255).astype(np.uint8)
    return out

# ============================= Inference =============================
def prepare_inputs(pil_img: Image.Image):
    pil = pil_img.convert("RGB").resize(IMG_SIZE)
    arr = np.array(pil, dtype=np.uint8)
    bchw_raw = np.expand_dims(arr.astype(np.float32), axis=0)  # ëª¨ë¸ ì…ë ¥ê³¼ ë™ì¼ ìŠ¤ì¼€ì¼
    bchw_pp  = preprocess_input(bchw_raw.copy())               # ë¶„ì„ìš©
    return arr, bchw_raw, bchw_pp

def predict_pneumonia_prob(model, bchw_raw):
    prob = model.predict(bchw_raw, verbose=0)
    if isinstance(prob, dict):
        prob = next(iter(prob.values()))
    if isinstance(prob, (list, tuple)):
        prob = prob[0]
    prob = np.asarray(prob).squeeze()
    return float(prob.item() if hasattr(prob, "item") else prob)

# ============================= Sidebar =============================
with st.sidebar:
    st.header("Settings")
    thresh = st.slider("Decision threshold (PNEUMONIA)", 0.50, 0.69, 0.50, 0.01)
    st.caption("â€¢ Lower = higher sensitivity for pneumonia\nâ€¢ Higher = fewer false positives")

    st.divider()
    st.subheader("Model fallback")
    st.caption("If download fails, upload your .keras model here and it will be cached.")
    uploaded_model = st.file_uploader("Upload model (.keras)", type=["keras"])

# ============================= Main UI =============================
st.title("Chest X-ray Pneumonia Classifier (DenseNet121)")
st.write("Upload a chest X-ray, get a prediction and Grad-CAM visualization. **This is not a medical device.**")

# 1) ëª¨ë¸ í™•ë³´
try:
    model_path = ensure_model_file_cached()
except Exception as e:
    st.warning(f"Auto-download failed: {e}")
    if uploaded_model is not None:
        tmp_path = MODEL_DIR / "uploaded_model.keras"
        with open(tmp_path, "wb") as f:
            f.write(uploaded_model.read())
        MODEL_LOCAL.unlink(missing_ok=True)
        tmp_path.rename(MODEL_LOCAL)
        st.success("âœ… Uploaded model saved.")
        model_path = str(MODEL_LOCAL)
    else:
        st.error("ëª¨ë¸ ìë™ íšë“ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ì‚¬ì´ë“œë°”ì—ì„œ .keras ëª¨ë¸ì„ ì—…ë¡œë“œí•´ ì£¼ì„¸ìš”.")
        st.stop()

# 2) ëª¨ë¸ ë¡œë“œ
try:
    model = load_model(model_path)
except Exception as e:
    st.error(f"Model load error: {e}")
    st.stop()

# 3) ì˜ˆì¸¡ UI
up = st.file_uploader("Upload an X-ray image (JPG/PNG)", type=["jpg", "jpeg", "png"])
if up is not None:
    pil_img = Image.open(up)
    rgb_uint8, x_raw_bchw, x_pp_bchw = prepare_inputs(pil_img)

    colA, colB = st.columns([1, 1])
    with colA:
        st.image(rgb_uint8, caption="Input (Resized 224Ã—224)", use_column_width=True)

    if st.button("Run inference"):
        with st.spinner("Running model..."):
            # ëª¨ë¸ í•œ ë²ˆ í˜¸ì¶œí•´ ê·¸ë˜í”„/shape ê³ ì •(ë¹Œë“œ)
            _ = model(x_raw_bchw, training=False)

            # ì˜ˆì¸¡
            p_pneu = predict_pneumonia_prob(model, x_raw_bchw)
            pred_label = CLASS_NAMES[1] if p_pneu >= thresh else CLASS_NAMES[0]
            conf = p_pneu if pred_label == "PNEUMONIA" else (1 - p_pneu)

            # DenseNet ì„œë¸Œëª¨ë¸ì—ì„œ 4D conv ì„ íƒ
            base = find_base_model(model)
            conv_layer = pick_best_densenet_conv_layer(base)
            if conv_layer is None:
                conv_layer = find_last_conv4d_layer_recursive(base)
            if conv_layer is None:
                conv_layer = find_last_conv4d_layer_recursive(model)

            # (ì„ íƒ) ë””ë²„ê·¸ìš©: í•„ìš” ì‹œ ì ê¹ë§Œ ì¼œì„¸ìš”
            # st.write("last conv:", conv_layer.name if conv_layer else "None")

            heatmap = make_gradcam_heatmap(x_raw_bchw, model, conv_layer)
            cam_img = overlay_heatmap(rgb_uint8, heatmap, alpha=0.45)

        with colB:
            st.image(cam_img, caption="Grad-CAM / Saliency (auto-fallback)", use_column_width=True)

        st.subheader("Prediction")
        col1, col2, col3 = st.columns(3)
        col1.metric("Predicted class", pred_label)
        col2.metric("Prob. PNEUMONIA", f"{p_pneu*100:.2f}%")
        col3.metric("Confidence", f"{conf*100:.2f}%")

        st.info(
            "â€¢ Threshold tuning: set **0.50** to prioritize catching pneumonia (higher sensitivity), "
            "or **0.69** to reduce false positives and protect normals.\n"
            "â€¢ Use alongside clinical judgment and radiologist review."
        )
else:
    st.caption("Awaiting an image uploadâ€¦")
